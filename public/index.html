<!DOCTYPE html>
<html lang="en">

<head>
    <title> #WhenWordsFail </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0" />
    <!-- Origin Trial Token, feature = WebVR (For Chrome M59+), origin = https://juniorxsound.github.io, expires = 2017-08-16 -->
    <meta http-equiv="origin-trial" data-feature="WebVR (For Chrome M59+)" data-expires="2017-08-16"
        content="Ahwo2B0LoM2bLB015eLJ4CAvJa0xF9VVn0FO1/AaYfPklvBUwcfYFkXKenD57vhGo1WQt9Hg9IFauhKdRgLN8w8AAABreyJvcmlnaW4iOiJodHRwczovL2p1bmlvcnhzb3VuZC5naXRodWIuaW86NDQzIiwiZmVhdHVyZSI6IldlYlZSMS4xIiwiZXhwaXJ5IjoxNTAyOTEyNTk5LCJpc1N1YmRvbWFpbiI6dHJ1ZX0=" />
    <link rel="stylesheet" type="text/css" href="assets/css/style.css" />

    <link rel="icon" type="image/x-icon"
        href="https://drive.google.com/drive/folders/1jELuofU2eiWYgu-pG_wb-O6YEBfK7x6T?usp=sharing">


</head>

<body onload="pageIsLoading()">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r115/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.1.9/p5.js"></script>
    <script src="js/OrbitControls.js"></script>
    <script src="js/depthkit.js"></script>

    <div id="loader">

    </div>

    <div id="info">
        <button id="submit-video" class="object"> </button>
        <!-- <button id="next" class="artifact"> </button> -->

        <div id="video-prompt" class="modal">
            <div class="modal-content">
                <span class="close">&times;</span>

                <div class="modal-body">
                    <div class="videos">
                        <h2 class="prompt"> What do you need to say? </h2>
                        <div id="video-placeholder">
                            <div id="recording"> </div>s
                        </div>
                    </div>
                </div>

                <div class="modal-body">
                    <div class="video-recording-suite">
                        <div class="upload-buttons">
                            <button id="submit" class="submit-button"> submit </button>
                            <button id="privacy" class="privacy-button"> pri-vacy </button>
                        </div>

                        <div class="record-buttons">
                            <button id="record" class="record-button"> rec </button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        let clock;
        
        function pageIsLoading() {
          clock = setTimeout(showPage, 3000);
        }
        
        function showPage() {
          document.getElementById("loader").style.display = "none";
          document.getElementById("info").style.display = "block";
        }
        </script>

    <script src="js/layout.js"></script>
    <script src="js/video.js"></script>
    <script id="vertShader" type="x-shader/x-vertex">
        #define GLSLIFY 1
        uniform float nearClip;
        uniform float farClip;
        uniform float width;
        uniform float height;
        uniform bool isPoints;
        uniform float pointSize;
        uniform float time;
        uniform vec2 focalLength;
        uniform vec2 principalPoint;
        uniform vec2 imageDimensions;
        uniform vec4 crop;
        uniform float meshScalar;
        uniform mat4 extrinsics;
        uniform sampler2D map;
        varying vec4 vPos;
        varying vec2 vUv;
        varying vec2 vUvDepth;
        varying float doIDiscard;

        float _DepthBrightnessThreshold = 0.5;  // per-pixel brightness threshold, used to refine edge geometry from eroneous edge depth samples
        #define BRIGHTNESS_THRESHOLD_OFFSET 0.01
        #define FLOAT_EPS 0.00001
        #define CLIP_EPSILON 0.005

        vec3 rgb2hsv(vec3 c)
        {
            vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
            vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));
            vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));
            float d = q.x - min(q.w, q.y);
            return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + FLOAT_EPS)), d / (q.x + FLOAT_EPS), q.x);
        }

        float depthForPoint(vec2 texturePoint)
        {
            vec2 centerpix = vec2(1.0/width, 1.0/height) * 0.5;
            texturePoint += centerpix;

            // clamp to texture bounds - 0.5 pixelsize so we do not sample outside our texture
            texturePoint = clamp(texturePoint, centerpix, vec2(1.0, 0.5) - centerpix);
            vec4 depthsample = texture2D(map, texturePoint);
            vec3 depthsamplehsv = rgb2hsv(depthsample.rgb);
            return depthsamplehsv.b > _DepthBrightnessThreshold + BRIGHTNESS_THRESHOLD_OFFSET ? depthsamplehsv.r : 0.0;
        }
        float random (in vec2 _st) {
            return fract(sin(dot(_st.xy,
                                 vec2(12.9898,78.233)))*
                43758.5453123);
        }

        float rand(float n){return fract(sin(n) * 43758.5453123);}

        float noise(float p){
            float fl = floor(p);
          float fc = fract(p);
            return mix(rand(fl), rand(fl + 1.0), fc);
        }
        float rand(vec2 n) {
            return fract(sin(dot(n, vec2(12.9898, 4.1414))) * 43758.5453);
        }

        float noise(vec2 p){
            vec2 ip = floor(p);
            vec2 u = fract(p);
            u = u*u*(3.0-2.0*u);

            float res = mix(
                mix(rand(ip),rand(ip+vec2(1.0,0.0)),u.x),
                mix(rand(ip+vec2(0.0,1.0)),rand(ip+vec2(1.0,1.0)),u.x),u.y);
            return res*res;
        }
        void main()
        {
            vec4 texSize = vec4(1.0 / width, 1.0 / height, width, height);
            vec2 basetex = position.xy;

            // we align our depth pixel centers with the center of each quad, so we do not require a half pixel offset
            vec2 depthTexCoord = basetex * vec2(1.0, 0.5);
            vec2 colorTexCoord = basetex * vec2(1.0, 0.5) + vec2(0.0, 0.5);

            // coordinates are always aligned to a multiple of texture sample widths, no need to clamp to topleft
            // unlike per-pixel sampling.
            float depth = depthForPoint(depthTexCoord);
            if (depth <= CLIP_EPSILON || ((1.0 - CLIP_EPSILON) >= depth))
            {
                // we use a 3x3 kernel, so sampling 8 neighbors
                //vec2 textureStep = 1.0 / meshScalar;
                vec2 textureStep = vec2(texSize.x * meshScalar, texSize.y * meshScalar);   // modify our texture step

                vec2 neighbors[8];
                neighbors[0] = vec2(-textureStep.x, -textureStep.y);
                neighbors[1] = vec2(0, -textureStep.y);
                neighbors[2] = vec2(textureStep.x, -textureStep.y);
                neighbors[3] = vec2(-textureStep.x, 0);
                neighbors[4] = vec2(textureStep.x, 0);
                neighbors[5] = vec2(-textureStep.x, textureStep.y);
                neighbors[6] = vec2(0, textureStep.y);
                neighbors[7] = vec2(textureStep.x, textureStep.y);

                // if this depth sample is not valid then check neighbors
                int validNeighbors = 0;
                float maxDepth = 0.0;
                for (int i = 0; i < 8; i++)
                {
                    float depthNeighbor = depthForPoint(depthTexCoord + neighbors[i]);
                    maxDepth = max(maxDepth, depthNeighbor);
                    validNeighbors += (depthNeighbor > CLIP_EPSILON || ((1.0 - CLIP_EPSILON) < depthNeighbor)) ? 1 : 0;
                }

                // clip to near plane if we and all our neighbors are invalid
                depth = validNeighbors > 0 ? maxDepth : 0.0;
            }

            vec2 imageCoordinates = crop.xy + (basetex * crop.zw);
            float z = depth * (farClip - nearClip) + nearClip; // transform from 0..1 space to near-far space Z
            vec2 ortho = imageCoordinates * imageDimensions - principalPoint;
            vec2 proj = ortho * z / focalLength;
            vec4 worldPos = extrinsics *  vec4(proj.xy, z, 1.0);
            worldPos.w = 1.0;

            gl_Position =  projectionMatrix * modelViewMatrix * worldPos;
                gl_PointSize = (10.- pow(worldPos.z*2.0,3.)) * 0.40;//distance(worldPos, vec4(0));
                //gl_Position.z -= (noise(gl_PointSize) * 3.-gl_PointSize) * 0.05;
        if(noise(gl_Position.yz*1000.) > 0.5){
            gl_Position.z += (noise(gl_PointSize) * 2.-gl_PointSize);
        }
        // if(noise(gl_Position.yz) > 0.5){
        //     gl_Position.z += (noise(gl_PointSize) * 2.-gl_PointSize);
        // }
        //gl_Position.z  *= sin(worldPos.x * 1000.)+0.1;
            vUv = colorTexCoord;
            vUvDepth = depthTexCoord;
            vPos = worldPos;//gl_Position.xyz;//(modelMatrix * vec4(gl_Position.xyz, 1.0)).xyz;//(modelMatrix * vec4(position, 1.0)).xyz;
        }
    </script>

    <script src="js/index.js"></script>
    <script src="js/howler.js"></script>
    <script>

        var sound = new Howl({
            src: ['/assets/audio/pagejamq.mp3'],
            autoplay: true,
            loop: true,
            volume: 0.08,
    });
</script>
</body>

</html>
